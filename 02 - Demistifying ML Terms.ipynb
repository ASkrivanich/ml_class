{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demistifying some ML terms for developers\n",
    "\n",
    "Machine Learning has a lot of new terminology that might not be used every day by many developers. \n",
    "Don't let these intimidate you.  Let's break a few of them down!\n",
    "\n",
    "# Vectors & Matrixes\n",
    "- Vectors: just a **column** in a spreadsheet - or a series - or a single array\n",
    "    > note: a vector can be horizontal or vertical, but for simplicity, we will use horizontal (column) vectors\n",
    "- Maxtrixes: just **spreadsheets** - or arrays of arrays - or a collection of vectors\n",
    "\n",
    "# Features\n",
    "- just the **variables** for each data record - the column names of your data. The data itself that the        feature represents is composed of a value like a string of characters or number\n",
    "- features can be **continuous** (prices, numbers, scales) or **categorical** (labels, class, lists, types, enums)\n",
    "\n",
    "![spreadsheet.png](images/spreadsheet.png)\n",
    "\n",
    "\n",
    "# Variable Naming Conventions for ML\n",
    "- **$\\mathbf X$** is a matrix of your data set - each row is a record & each column is a feature\n",
    "- **$\\mathbf y$** is a vector of the truth labels or values (eg. actual known sale price of a house, or the correct class label 'Lightning McQueen')\n",
    "- **$\\mathbf{\\hat y}$** _(y-hat)_ is a vector of your models predictions (values or labels)\n",
    "- **Shape** is the dimensions of your matrix. \n",
    "  - If you have a dataframe with 100 items and 3 feature columns, shape would be (100,3)\n",
    "  \n",
    "  \n",
    "# Derivatives\n",
    "- just the gradient or **slope of line** at a given point on the graph\n",
    "\n",
    "## Visual Example\n",
    "> don't worry about the code yet--this is just to play around with the idea of a derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pylab import plot,show\n",
    "from scipy import interpolate\n",
    "\n",
    "### --- The Walt Disney Company movies produced each year --- ###\n",
    "\n",
    "# format:  [Year, Number]\n",
    "data = np.array([[1937,1],[1938,0],[1939,0],[1940,2],[1941,0],[1942,0],[1943,0],[1944,0],\n",
    "                 [1945,0],[1946,1],[1947,0],[1948,0],[1949,0],[1950,1],[1951,0],[1952,0],\n",
    "                 [1953,0],[1954,1],[1955,1],[1956,0],[1957,0],[1958,0],[1959,1],[1960,0],\n",
    "                 [1961,3],[1962,1],[1963,1],[1964,0],[1965,0],[1966,0],[1967,1],[1968,1],\n",
    "                 [1969,0],[1970,2],[1971,1],[1972,0],[1973,0],[1974,0],[1975,1],[1976,0],\n",
    "                 [1977,4],[1978,0],[1979,1],[1980,3],[1981,4],[1982,3],[1983,4],[1984,2],\n",
    "                 [1985,6],[1986,7],[1987,10],[1988,12],[1989,11],[1990,15],[1991,16],[1992,22],\n",
    "                 [1993,27],[1994,30],[1995,32],[1996,28],[1997,23],[1998,22],[1999,21],[2000,19],\n",
    "                 [2001,14],[2002,22],[2003,19],[2004,19],[2005,17],[2006,18],[2007,14],[2008,13],\n",
    "                 [2009,16],[2010,14],[2011,14],[2012,10],[2013,10],[2014,13],[2015,11],[2016,14],\n",
    "                 [2017,9],[2018,11]])\n",
    "# Showing Derivative slope tangent line\n",
    "# Adapted from post at https://glowingpython.blogspot.com/2013/02/visualizing-tangent.html\n",
    "def draw_tangent(x,y,a,color):\n",
    " # interpolate the data with a spline\n",
    " spl = interpolate.splrep(x,y)\n",
    " small_t = np.arange(a-5,a+5)\n",
    " fa = interpolate.splev(a,spl,der=0)     # f(a)\n",
    " fprime = interpolate.splev(a,spl,der=1) # f'(a)\n",
    " tan = fa+fprime*(small_t-a) # tangent\n",
    " plot(a,fa,'om',small_t,tan,'--'+color)\n",
    "\n",
    "# use python's slicing to select all rows from column 0 \n",
    "year = data[:,0]\n",
    "# use python's slicing to select all rows from column 1\n",
    "num_movies = data[:,1]\n",
    "\n",
    "# now let's draw a tangent line\n",
    "# you can change these year values to see it move on the plot below\n",
    "draw_tangent(year,num_movies,1951,'k')\n",
    "draw_tangent(year,num_movies,1998,'r')\n",
    "\n",
    "plot(year,num_movies,alpha=0.5)\n",
    "show()\n",
    "\n",
    "# Now it's your turn to play around. Update the years above and hit ctrl+enter to run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost and Loss Functions\n",
    "- a way to calculate **how much error** the current model iteration has\n",
    "- a way to graph how well your model fits your data as you adjust your model's variables to various values searching for lowest cost/loss\n",
    "\n",
    "- Additional visualizations of derivatives, gradient descent, and cost functions:\n",
    "https://medium.com/onfido-tech/machine-learning-101-be2e0a86c96a\n",
    "\n",
    "# Gradient Descent\n",
    "- just taking the fastest way down the hill - imagine taking a 360 degree look around & then taking a small step in the steepest direction\n",
    "- good examples visualizing & animating this at: http://tiao.io/notes/visualizing-and-animating-optimization-algorithms-with-matplotlib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "kwargs = {'modestbranding': 1, 'rel':0, 'end':22}\n",
    "YouTubeVideo('vWFjqgb-ylQ',start=4, width=500,height=300,**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "- Predicting a continuous output value based on input variables\n",
    "  -  eg. Predict a Guest's 'spend' at Disney World based on how many 'days' they attend the parks\n",
    "\n",
    "# Multivariate Linear Regression\n",
    "Sounds complex but lets break it down :)\n",
    "- Regression: a continous value output\n",
    "- Linear: it uses a linear function to plot the line that fits your data\n",
    "- Multivariate: multiple input variables (not just one)\n",
    "\n",
    "![image.png](images/regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy\n",
    "- Accuracy: What percent of all your predictions are correct?\n",
    "  - **Beware this may not be the best measure for your model**\n",
    "  \n",
    "  ###  **Importance of Recall and Precision vs Accuracy**\n",
    "  - **Accuracy does not work for unbalanced classification data** (where there are more of one class than the other)\n",
    "    - If you expect to see 1 security anomaly event for every 100,000 normal user events, you can achieve 99.999% _accuracy_ by coding a model that just predicts \"_NO_\" all the time.\n",
    "  - this is a good metric if the truth is a 50/50 ratio (e.g. saying \"_NO_\" 100% of the time when asked if a random human is male has an accuracy of ~50%)\n",
    "\n",
    "# Recall\n",
    "- Recall: Measures how well we do finding all the possible needles\n",
    "  - How many needles can we find in the haystack?\n",
    "  - What percent of the _all the needles_ did we find (classify as a needle)?\n",
    "  > you can get 100% Recall by always saying \"Yes\" - but your Precision will be 0\n",
    "\n",
    "# Precision\n",
    "- Precision: Measures how well we do when we claim something is a needle\n",
    "  - How many predicted needles _really are_ needles?\n",
    "  - What percent of our 'true' needle predictions are really needles?\n",
    "  > you can get 100% Precision by always saying \"No\" - but your Recall will be 0\n",
    "  \n",
    "\n",
    "![precision_recall.jpg](images/precision_recall.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Up\n",
    "[Regression or Classification?](/notebooks/03%20-%20Regression%20or%20Classification.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
