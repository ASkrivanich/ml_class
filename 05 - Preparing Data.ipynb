{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data\n",
    "Your Model is Only as Good as the Training Data\n",
    "Garbage in is Garbage out.  Let's avoid garbage intake.\n",
    "It's important to 'scrub' your data to get it into a clean state where it provides value to training the model for machine learning.\n",
    "## Data Usually Contains Bugs/Outliers\n",
    "\n",
    "You will likely spend most of your time in machine learning messing around with the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretend we have some housing price data in the form of `[square footage, sale price]`, and we notice a strange outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "    [900,300000],\n",
    "    [1200,400000],\n",
    "    [980,1400000],\n",
    "    [1500,480000],\n",
    "    [1800,510000],\n",
    "    [2200,550000],\n",
    "    [2400,600000]]\n",
    ")\n",
    "df.columns = ['Square Footage','Sale Price']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot it so we can quickly see the problem\n",
    "%matplotlib notebook\n",
    "plt.xlabel('Square Footage')\n",
    "plt.ylabel('Sale Price in $')\n",
    "plt.plot(df['Square Footage'].values,df['Sale Price'].values,'rx');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see above that there is an outlier in the data--a point that doesn't fit the pattern of the other data points and may be a case we don't want to support in our model.\n",
    "\n",
    "In this case, let's imagine that item #2, the house with a square footage of 980, which sold for $1.4M is an unusual exception--and we found in the data that this was a private sale of a famous historical home. This data isn't something we want to consider in our evaluation. If we had a very large training set, this one outlier probably wouldn't hurt our training, but if we have only a few hundred or thousand examples, it can throw us off our prediction target unnecessarily.\n",
    "\n",
    "Before running ML on your data, find the outliers and decide at what point you want to cut off and restrict the anomalies to create a \"normalized\" set of data.\n",
    "You may want to build a special model to analyse extremely different groupings of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# Let's see what it looks like if we exclude the anomaly\n",
    "df = pd.DataFrame([\n",
    "    [900,300000],\n",
    "    [1200,400000],\n",
    "    #[980,1400000],\n",
    "    [1500,480000],\n",
    "    [1800,510000],\n",
    "    [2200,550000],\n",
    "    [2400,600000]]\n",
    ")\n",
    "df.columns = ['Square Footage','Sale Price']\n",
    "plt.xlabel('Square Footage')\n",
    "plt.ylabel('Sale Price in $')\n",
    "plt.plot(df['Square Footage'].values,df['Sale Price'].values,'rx');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data into Train and Test Sets\n",
    "You will need to segment your data into a training set (for teaching the model) and a test/eval set for evaluating the model. Both of these datasets need to have all of the truth data you are trying to predict.\n",
    "Make sure to hold out some of your truth data for evaluation.\n",
    "> evaluations using the same data as the training data will not give an accurate report of the efficacy of your model (you may be over or under fitting the data but the eval step will fail to give a bad score)\n",
    "\n",
    "Some libraries like scikit-learn have utilities for helping to split and manage your data.\n",
    "In the next example, we'll use [sklearn.model_selection.train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Up\n",
    "\n",
    "[Regression Examples](06 - Regression Examples.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
