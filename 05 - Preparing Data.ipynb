{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data\n",
    "Your Model is Only as Good as the Training Data\n",
    "Garbage in is Garbage out.  Let's avoid garbage intake.\n",
    "It's important to 'scrub' your data to get it into a clean state where it provides value to training the model for machine learning.\n",
    "## Data Usually Contains Bugs/Outliers\n",
    "\n",
    "You will likely spend most of your time in machine learning messing around with the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's pretend we have captured a set of data that tells \n",
    "# how many unique User Agents we found associated with IP addresses\n",
    "df = pd.DataFrame([[1,2],[3,6],[5,10],[6,12],[7,14],[32,1],[8,16]])\n",
    "df.columns = ['Unique User Agents','Unique IPs']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see above that there is an outlier in the data--a point that doesn't fit the pattern of the other data points and may be a case we don't want to support in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outlier might be a college campus, with thousands of users (and probably a lot of junk traffic with user-agent spoofing), but only 1 outbound IP address. This is an example of an outlier that will fool your model into thinking that this is a normal event that has the same wieght as everything else. Before running ML on your data, find the outliers and decide at what point you want to cut off and restrict the anomalies to create a \"normalized\" set of data.\n",
    "You may want to build a special model to analyse extremely different groupings of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what it looks like if we exclude the anomaly\n",
    "df = pd.DataFrame([[1,2],[3,6],[5,10],[6,12],[7,14],[8,16]]);\n",
    "df.columns = ['Unique User Agents','Unique IPs'];\n",
    "df.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data into Train and Test Sets\n",
    "You will need to segment your data into a training set (for teaching the model) and a test/eval set for evaluating the model. Both of these datasets need to have all of the truth data you are trying to predict.\n",
    "Make sure to hold out some of your truth data for evaluation.\n",
    "> evaluations using the same data as the training data will not give an accurate report of the efficacy of your model (you may be over or under fitting the data but the eval step will fail to give a bad score)\n",
    "\n",
    "Some libraries like scikit-learn have utilities for helping to split and manage your data.\n",
    "In the next example, we'll use [sklearn.model_selection.train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Up\n",
    "\n",
    "[Regression Examples](/notebooks/06 - Regression Examples.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
